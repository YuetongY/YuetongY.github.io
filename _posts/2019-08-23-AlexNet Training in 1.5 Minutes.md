---
layout:default
title:Paper Review: Optimizing Network Performance for Distributed DNN Training on GPU Clusters:ImageNet/AlexNet Training in 1.5 Minutes
---
#论文：《Optimizing Network Performance for Distributed DNN Training on GPU Clusters:ImageNet/AlexNet Training in 1.5 Minutes》
##内容梳理
###主要贡献
这篇文章主要介绍了一个能够在1.5分钟内完成AlexNet在ImageNet数据集上训练过程的系统。实现该系统，作者使用了一些前人已经提出的方法或理念，主要包括：
1.	Ring-Based allreduce
2.	混合精度训练
3.	Tensor Fusion
4.	通信与计算的重叠
作者在文章中，使用了大量篇幅对使用上述方法的性能进行了详细的对比叙述，指出了各种方法的优缺点。
作者在分析了之前那些方法在实现上的缺点之后，提出了两个方法，以提高通信性能：
1.	lazy allreduce
2.	粗粒度的稀疏通信
其中lazy allreduce与之前有的学者已经提到的tensor fusion非常类似，而且在Horovod中已经有了使用，但是在Horovod的使用中，存在着将buffer重复复制的问题，大大降低了效率。lazy allreduce在我的理解看来，主要是共享了内存地址空间，可以减少buffer复制的问题。其核心理念还是设定一个阈值，待缓存大小达到阈值之后再进行all reduce，以增加带宽利用率。
###主要问题
文章在性能对比的过程中，往往只关注吞吐量，关注单位时间了单个GPU能够处理多少张图片，以体现性能差距，但是对于最后训练得到的模型的性能，文中没有详细的对比。
###核心方法
####基本方法概括
文章对分布式深度学习领域的各种基本方法，都进行了较为详细的对比实验，简要概括如下：
- 不适用任何优化的情况下（基于Gloo作为通信后端的PyTorch或基于OpenMPI的内部系统）
	- 加速比很低，且MPI通信要强于Gloo通信。
- 使用Ring-Based allreduce
	- 能够在Tensor Size**比较大**的时候提高加速比
	- NCCL的表现要相较于MPI好很多
	- 距离理想值还有差距
- 使用混合精度训练
	- 使用半精度训练理论上能够提高1倍吞吐量
	- 对于参数量较小的ResNet-50网络，有着较高的加速比
	- 对于参数量较大的AlexNet网络，由于存在着大量的精度转换操作，加速比没有ResNet-50那么高
- 计算与通信重叠
	- 对提高加速比有一定的帮助，但是距离理想加速比还有很大差距
#### 提出的核心方法
作者在上面的一系列方法的实现中，发现了两个主要的问题：
1. 对非常小的梯度向量进行allreduce的过程，网络带宽利用率不高
2. 在AlexNet中的DNN网络中，由于参数量过大，对网络通信的压力会很大

解决第一个问题，文中提出了一种lazy allreduce的方法，刚才已经提到过，其实和tensor fusion差别不大。
在解决第二个问题上，文中提到了一种不能在分布式训练系统上适用的通信方法，称为*fine-grained sparse communication(FCS)*，这种方法的核心思想是只使用那些比较大的梯度进行模型参数的更新，舍弃那些比较小的梯度。这样可以大大减少通信量。为了减少通信量，可以用k-v这种方式保存需要对某个位置的模型参数进行何种更新，但是这样是非常不利于GPU的计算的，GPU对稠密的矩阵的运算有着很高的效率，对于稀疏的矩阵的运算效率很低。
作者在上面的方法上提出了一种粗粒度的稀疏通信方式解决参数量过大的情况下梯度同步的问题。核心的思想是将每一层计算得到的梯度向量进行分块，选择那些比较重要的块中的梯度作为需要同步的梯度，最后对那些重要的块中的梯度对应的模型参数进行更新。
衡量某个块是否重要的方法是计算出所有节点上对应块的梯度之后，求出这些梯度向量的1-范数，每一个1-范数相当于是这个块在这个节点上的重要性。之后对每个节点上的各个块的1-范数进行平均，得到各个块的整体重要性。
需要注意的是，在重要性平均的过程中，也使用了Ring based allreduce的操作。
